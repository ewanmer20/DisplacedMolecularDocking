
from Analysis_lib import*
from Generate_samples import*
from time import time

#Loading samples generated by Generate_samples.py file
cwd_data='Alpha_Variation'
alpha=np.linspace(0.1,10,10)
#Using the adjacency matrix  to be consistent with the GBS simulation
Adj =data.TaceAs().adj

#Retrieving the potential values for the adjacency matrix
weights=make_potential_vect()

#Find the maximum clique with classical algorithm

cwd_big='big\\big_tau1.1_.csv'
BIG=log_data(cwd_big)
clique_max,clique_weight=find_max_clique(BIG,weights,networkx_conv=False)
print('clique_max',clique_max)
print('clique_weight',clique_weight)


for i in range(10):
    excel_file=cwd_data+'\\'+'nsamples=100000.0_nsubspace=24.0alpha={:.1f}loss=0.50_samples_cov.csv'.format(alpha[i])
    samples=log_data(excel_file)
    # Histogram of the number of photons per sample
    a, nmax = plot_histogram(samples, plot=False)
    # #Remove the non-zero clicks event and the collision events
    cleaned_samples, ncollision = clean_samples(samples, nmax)
    print(len(cleaned_samples))
    print(ncollision)
    print(a)
    plot_success_rate_vs_niter(cleaned_GBS_samples=cleaned_samples, nmax=nmax, Adj=BIG, weights=weights, niter=10)
    print('Iteration number:{:.2f}'.format(i))

