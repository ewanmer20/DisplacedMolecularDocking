from Analysis_lib import*
from Generate_samples import*
from time import time
#Loading samples generated by Generate_samples.py file
cwd='Results\\24-Aug-2022-(20.48.26.584363)\\'
excel_file=cwd+'nsamples=100000.0_nsubspace=24.0alpha=2.1loss=0.00ncoh=3.999892_displaced_samples_cov.csv'
TA=log_data(excel_file)[:500]
print(TA[:10])
#Loading the graph from TaceAs problem

#Using the adjacency matrix reduced to the first 10 modes to be consistent with the GBS simulation
Adj =data.TaceAs().adj

#Retrieving the potential values for the adjacency matrix
weights=make_potential_vect()

# Histogram of the number of photons per sample
a,nmax=plot_histogram(TA,plot=False)
print(a)

# #Remove the non-zero clicks event and the collision events
cleaned_GBS_samples,ncollision=clean_samples(TA,nmax)
print(len(cleaned_GBS_samples))
print(ncollision)
niter=10

# # Histogram of the number of photons per sample
# a,nmax2=plot_histogram(cleaned_samples,plot=False)
# print(a)






t0=time()
if len(weights)!=len(Adj):
    raise Exception("Weigths and Adj needs the same length")
_,_,photo_dist=plot_histogram(cleaned_GBS_samples,plot=False,phot_dist=True)
print('mean',np.mean(photo_dist))
print('std',np.std(photo_dist))
samples_uni=[list(np.random.choice(len(Adj),np.abs(photo_dist[i]),replace=False)) for i in range(len(cleaned_GBS_samples))] # generates uniform samples in the networkx convention
print('samples_uni', samples_uni[:10])
max_clique_sample_nxconv=find_max_clique(Adj,weights,networkx_conv=True) #The maximum clique
print('max_clique',max_clique_sample_nxconv)

graph_ref=nx.Graph(Adj)

cleaned_samples_copy=copy.deepcopy(cleaned_GBS_samples)
subgraph_GBS = sample.to_subgraphs(cleaned_samples_copy,graph_ref)
shrunk_GBS = [clique.shrink(s, graph_ref) for s in subgraph_GBS]
print('searched_GBS',subgraph_GBS[:20])
searched_uni=copy.deepcopy(samples_uni)

shrunk_uni = [clique.shrink(s, graph_ref) for s in searched_uni]
print('searched_uni',searched_uni[:20])
succ_rate_GBS = [count_clique_occurence_networkx(shrunk_GBS, max_clique_sample_nxconv)/(len(shrunk_GBS))*100]  # Comparison
succ_rate_uni = [count_clique_occurence_networkx(shrunk_uni, max_clique_sample_nxconv)/(len(shrunk_uni))*100]

searched_GBS = [clique.search(clique=s, graph=graph_ref, iterations=1, node_select=weights) for s in shrunk_GBS]
print('a', searched_GBS[:10])
succ_rate_GBS.append(count_clique_occurence_networkx(searched_GBS, max_clique_sample_nxconv) / (
    len(searched_GBS)) * 100)  # Count the occurences of the max clique in the networkx convention
searched_GBS = [sample for sample in searched_GBS if is_clique_networkx(sample,max_clique_sample_nxconv)==False]
print('a',searched_GBS[:10])
succ_rate_GBS.append((len(shrunk_GBS) - len(searched_GBS)) / (
    len(shrunk_GBS)) * 100)  # Count the occurences of the max clique in the networkx convention
searched_uni = [clique.search(clique=s, graph=graph_ref, iterations=1, node_select=weights) for s in shrunk_uni]
succ_rate_uni.append(count_clique_occurence_networkx(searched_uni, max_clique_sample_nxconv) / (
    len(searched_uni)) * 100)  # Count the occurences of the max clique in the networkx convention
searched_uni =[sample for sample in searched_uni if is_clique_networkx(sample, max_clique_sample_nxconv) == False]
succ_rate_uni.append((len(shrunk_uni) - len(searched_uni)) / (
    len(shrunk_uni)) * 100)  # Count the occurences of the max clique in the networkx convention
for i in range(1,niter):
    print(type(searched_GBS))
    searched_GBS = [clique.search(clique=s, graph=graph_ref,iterations=1,node_select=weights) for s in searched_GBS]
    searched_GBS = [sample for sample in searched_GBS if is_clique_networkx(sample, max_clique_sample_nxconv) == False]

    succ_rate_GBS.append((len(shrunk_GBS) - len(searched_GBS)) / (len(shrunk_GBS)) * 100)  # Count the occurences of the max clique in the networkx convention
    # succ_rate_GBS.append(count_clique_occurence_networkx(searched_GBS,max_clique_sample_nxconv)/(len(searched_GBS))*100)#Count the occurences of the max clique in the networkx convention
    # clique_rate_GBS.append(sum([clique.is_clique(graph_ref.subgraph(s)) for s in searched_GBS]))
    searched_uni = [clique.search(clique=s, graph=graph_ref,iterations=1,node_select=weights) for s in searched_uni]
    searched_uni = [sample for sample in searched_uni if is_clique_networkx(sample, max_clique_sample_nxconv) == False]
    succ_rate_uni.append((len(shrunk_uni) - len(searched_uni)) / (len(shrunk_uni)) * 100)  # Count the occurences of the max clique in the networkx convention
    # succ_rate_uni.append(count_clique_occurence_networkx(searched_uni,max_clique_sample_nxconv)/ (len(searched_uni)) * 100) #Count the occurences of the max clique in the networkx convention
    # clique_rate_uni.append(sum([clique.is_clique(graph_ref.subgraph(s)) for s in searched_uni]))
t1=time()
print(t1-t0)
print(succ_rate_uni)
print(succ_rate_GBS)

fig,ax=plt.subplots(nrows=1,ncols=1,figsize=(16,16))
ax.plot(np.array(succ_rate_GBS),label='GBS samples networkx',color='g')
ax.plot(np.array(succ_rate_uni),label='Uniform samples',color='r')
# ax.plot(np.array(clique_rate_uni)/len(cleaned_GBS_samples)*100,'r--',label='Uniform samples bound',)
# ax.plot(np.array(clique_rate_GBS)/len(cleaned_GBS_samples)*100,'g--',label='GBS samples bound')
ax.set_xlabel('Iteration step of local search algorithm')
ax.set_ylabel('Success rate (%)')
plt.legend()
