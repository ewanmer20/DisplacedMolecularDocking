
from Analysis_lib import*
from Generate_samples import*
from time import time

#Loading samples generated by Generate_samples.py file
# cwd='Reference_samples\\'
# excel_file=cwd+'Reference_mean_n=0.89 nsamples=100000.0_nsubspace=10.0_samples_cov.csv'
# tot_samples=log_data(excel_file)

#Loading the graph from TaceAs problem
TA = np.array(postselect(data.TaceAs()[:20000],8,19))
print(TA[:2])
#Using the adjacency matrix reduced to the first 10 modes to be consistent with the GBS simulation
Adj =  data.TaceAs().adj

#Retrieving the potential values for the adjacency matrix
weights=make_potential_vect()



# Histogram of the number of photons per sample
a,nmax=plot_histogram(TA,plot=False)
print(a)

# #Remove the non-zero clicks event and the collision events
# cleaned_samples,ncollision=clean_samples(tot_samples,nmax)
# print(len(cleaned_samples))
# print(ncollision)
#
# # Histogram of the number of photons per sample
# a,nmax2=plot_histogram(cleaned_samples,plot=False)
# print(a)


#Find the maximum clique with classical algorithm
clique_max,clique_weight=find_max_clique(Adj,weights,networkx_conv=False)
print('clique_max',clique_max)
print('clique_weight',clique_weight)
cwd='big\\big_tau1.1_.csv'
BIG=log_data(cwd)
print(BIG)

plot_success_rate_vs_niter(cleaned_GBS_samples=TA,nmax=nmax,Adj=BIG,weights=weights,niter=20)
# plot_histogram_clique_values(cleaned_samples,nmax,Adj,weights)
# samples_GBS=postselect(tot_samples,postselection_number+4,postselection_number+4) # Postselecting the samples according the number of clicks

# print(samples_GBS)
#
#

