import traceback  # For displaying exceptions
import os
import logging
from log_utils import LogUtils
from datetime import datetime  # For current day and time
from datetime import date
from time import time  # For runtime of scripts

from strawberryfields.apps import data, plot, sample, clique
from strawberryfields.apps.sample import postselect
from strawberryfields.decompositions import takagi
from scipy.sparse.csgraph import laplacian
from thewalrus.samples import hafnian_sample_graph
import numpy as np
import networkx as nx
import csv
import plotly
from Analysis_lib import*
from Generate_samples import*
from strawberryfields.apps.clique import is_clique


# #Using the adjacency matrix reduced to the first 10 modes to be consistent with the GBS simulation
# Adj = TA.adj[:10,:10]
# graph=nx.Graph(Adj)
# list_samples=[[5,4,6],[4,5,6],[2,3,4],[4,5,6,7]]
# clique_test=[5,4,6]
#
# print(count_clique_occurence_networkx(list_samples,clique_test,graph))

#Loading samples generated by Generate_samples.py file
cwd='Reference_samples\\'
excel_file=cwd+'Reference_mean_n=0.89 nsamples=100000.0_nsubspace=10.0_samples_cov.csv'
tot_samples=log_data(excel_file)

#Loading the graph from TaceAs problem
TA = data.TaceAs()

#Retrieving the potential values for the adjacency matrix
weights=make_potential_vect()[:10]
print(weights)
#Using the adjacency matrix reduced to the first 10 modes to be consistent with the GBS simulation
Adj = TA.adj[:10,:10]
for i in range(len(Adj)):
    Adj[i,i]=weights[i]
graph_ref=nx.from_numpy_matrix(Adj)
print(graph_ref.nodes[0])


# Histogram of the number of photons per sample
a,nmax=plot_histogram(tot_samples,plot=False)
print(a)

#Remove the non-zero clicks event and the collision events
cleaned_samples,ncollision=clean_samples(tot_samples,nmax)
print(len(cleaned_samples))
print(ncollision)

max_clique_sample_nxconv=find_max_clique(Adj,weights,networkx_conv=True) #The maximum clique
print('max_clique',max_clique_sample_nxconv)

# print('test',nx.is_isomorphic(graph_ref.subgraph(max_clique_sample_nxconv),graph_ref.subgraph([1,2,4,6,7,8])))
#
# searched_GBS=copy.deepcopy(cleaned_samples[:100])
# shrunk_GBS = np.array([clique.shrink(s, graph_ref) for s in searched_GBS])
# searched_GBS = np.array([clique.search(s, graph_ref,1) for s in shrunk_GBS])
# count=0
# for s in searched_GBS:
#      a=count_clique_occurence_networkx1(np.array([s]),max_clique_sample_nxconv,graph_ref)
#      b=count_clique_occurence_networkx2(np.array([s]),max_clique_sample_nxconv,graph_ref)
#      if a!=b:
#          print(s)
#          print('Graph',a)
#          print('Sort',b)
#          count+=1
# print(count)
#
